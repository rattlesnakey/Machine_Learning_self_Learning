{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证得分:[0.83333333 0.95       1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#导入红酒数据集\n",
    "from sklearn.datasets import load_wine\n",
    "#导入交叉验证工具\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#导人用于分类的支持向最机模型\n",
    "from sklearn.svm import SVC\n",
    "#载入红酒数据集\n",
    "wine = load_wine ()\n",
    "#设置SVC的核函数为linear\n",
    "SVC= SVC(kernel =\"linear\")\n",
    "#使用交叉验证法对SVC 进行评分．\n",
    "scores = cross_val_score(SVC,wine.data,wine.target)\n",
    "#打印结果\n",
    "print (\"交叉验证得分:{}\". format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下是3折交叉验证法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9277777777777777"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证得分:[0.86666667 0.9        0.93333333 0.96666667 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "#使用交叉验证法对SVC 进行评分．\n",
    "scores = cross_val_score(SVC,wine.data,wine.target,cv=6)#参数Cv是用来看你要几折验证\n",
    "#打印结果\n",
    "print (\"交叉验证得分:{}\". format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用了cross validation的话，其实就不用再用train_test_split了\n",
    "\n",
    "\n",
    "从结果中可以看出，如果用不分层的k 折叠的交叉验证法，那么在拆\n",
    "分数据集的时候，有可能每个子集中都是同一个标签，这样的话模型评分都不会太高。\n",
    "而分层k 折叠交叉验证法的优势在于，它会在每个不同分类中进行拆分，确保每个子集\n",
    "中都有数量基本一致的不同分类标签。举例来说，假如你有一个人口性别数据集，其中\n",
    "有80% 是“男性”，只有20% 是“女性”，分层k 折叠交叉验证法会保证在你的每个子\n",
    "集中，都有80% 的男性，其余20% 是女性。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "分层交叉验证的话就可以保证每个部分的数据集各个类别的比例都是和原数据当中各个类别的比例一样的"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "shufflesplit 和leave one out都是交叉验证的一种\n",
    "\n",
    "shufflesplit就是它是每次随机从数据集中按训练集是多少的比例，测试集是多少的比例来训练\n",
    "\n",
    "leave one out 其实和k折交叉验证有点像，只是它是一以数据集当中的每个样本为测试集其余为训练集来进行迭代测试，时间会很久"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "现在读者朋友可能在想，既然我们有了位ain_test_ split，为什么还要使用交叉验证法\n",
    "呢？毕竟交叉验证法最后对模型进行的评分也只是一个平均数而已啊！\n",
    "原因是这样的：当我们使用位ain_test_ split 方法进行数据集的拆分时， train_test_ splt\n",
    "用的是随机拆分的方法，万一我们拆分的时候，测试集中都是比较容易进行分类或者回\n",
    "归的数据，而训练集中都比较难，那么模型的得分就会偏高，反之模型的得分就会偏低。\n",
    "我们又不太可能把所有的random state 遍历一遍。而交叉验证法正好弥补了这个缺陷，\n",
    "它的工作原理导致它要对多次拆分进行评分再取平均值，这样就不会出现我们前面所说\n",
    "的问题。\n",
    "此外， train_test_ split 总是按照25% ～ 75% 的比例来拆分训练集与测试集（默认情\n",
    "况下），但当我们使用交叉验证法的时候， 可以更加灵活地指定训练集和测试集的大小，\n",
    "比如当CV 参数为10 的时候，训练集就会占整个数据集的90% ，测试集占10%; CV 参数\n",
    "为20 的时候，训练集的占比就会达到95% ，而测试集占比5% 。这也意味着训练集会更大，\n",
    "对于模型的准确率也有促进的作用。\n",
    "不过交叉验证法往往要比train_test_ split 更加消耗计算资源，如果读者朋友按上面的\n",
    "代码进行了实验，就会发现交叉验证法比train_test_ split 要隆一些。所以在实际应用中，\n",
    "大家可以灵活使用这两种方法来对模型进行评估。\n",
    "接下来，我们要介绍的是如何调整模型的参数，让分数更高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
